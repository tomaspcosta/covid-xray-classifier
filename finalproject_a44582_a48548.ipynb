{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install required packages\n",
    "%pip install torch>=2.0.0 torchvision>=0.15.0 scikit-learn>=1.0 numpy>=1.21 Pillow>=9.0 argparse>=1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/10, Loss: 0.6160\n",
      "Epoch 2/10, Loss: 0.3063\n",
      "Epoch 3/10, Loss: 0.1090\n",
      "Epoch 4/10, Loss: 0.0602\n",
      "Epoch 5/10, Loss: 0.0384\n",
      "Epoch 6/10, Loss: 0.0482\n",
      "Epoch 7/10, Loss: 0.1824\n",
      "Epoch 8/10, Loss: 0.0230\n",
      "Epoch 9/10, Loss: 0.0318\n",
      "Epoch 10/10, Loss: 0.0204\n",
      "Training completed.\n",
      "Validating model...\n",
      "Class distribution in validation set: {np.int64(0): np.int64(28), np.int64(1): np.int64(23)}\n",
      "True labels: [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0)]\n",
      "Predicted labels: [np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0)]\n",
      "Validation F1 Score (basic): 100.0000%\n",
      "Validation Weighted F1 Score: 1.0000\n",
      "Evaluating model on unseen data...\n",
      "Evaluation completed. Results saved to c:\\Users\\jtoma\\Desktop\\si-project\\result.txt\n"
     ]
    }
   ],
   "source": [
    "# setting paths and seeding\n",
    "BASE_DIR = os.getcwd()\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'covid_dataset', 'train')\n",
    "EVAL_DIR = os.path.join(BASE_DIR, 'evaluation_Set')\n",
    "RESULT_FILE = os.path.join(BASE_DIR, 'result.txt')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# check if required directories exist\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    raise FileNotFoundError(f\"Training directory not found: {TRAIN_DIR}\")\n",
    "if not os.path.exists(EVAL_DIR):\n",
    "    raise FileNotFoundError(f\"Evaluation directory not found: {EVAL_DIR}\")\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]) \n",
    "])\n",
    "\n",
    "# load training dataset\n",
    "train_data = datasets.ImageFolder(TRAIN_DIR, transform=transform)\n",
    "\n",
    "# stratified split\n",
    "labels = [label for _, label in train_data]\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(train_data)),\n",
    "    test_size=0.2, \n",
    "    stratify=labels,  \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "# subset datasets\n",
    "train_dataset = torch.utils.data.Subset(train_data, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(train_data, val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# load evaluation dataset\n",
    "def load_eval_images(eval_dir):\n",
    "    return [os.path.join(eval_dir, fname) for fname in os.listdir(eval_dir) if fname.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "eval_image_paths = load_eval_images(EVAL_DIR)\n",
    "\n",
    "class EvalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        return image, os.path.basename(img_path)\n",
    "\n",
    "eval_dataset = EvalDataset(eval_image_paths, transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# model: ResNet18\n",
    "model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# training function\n",
    "def train_model(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# validation function\n",
    "def validate_model():\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    unique, counts = np.unique(val_labels, return_counts=True)\n",
    "    print(\"Class distribution in validation set:\", dict(zip(unique, counts)))\n",
    "\n",
    "    print(\"True labels:\", val_labels)\n",
    "    print(\"Predicted labels:\", val_preds)\n",
    "\n",
    "    # calculate F1 score\n",
    "    val_f1 = f1_score(val_labels, val_preds)\n",
    "    print(f\"Validation F1 Score (basic): {val_f1 * 100:.4f}%\")\n",
    "\n",
    "    # weighted F1 score\n",
    "    val_f1_weighted = f1_score(val_labels, val_preds, average='weighted')\n",
    "    print(f\"Validation Weighted F1 Score: {val_f1_weighted:.4f}\")\n",
    "\n",
    "    return val_f1\n",
    "\n",
    "# evaluation function\n",
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    with open(RESULT_FILE, 'w') as f:\n",
    "        with torch.no_grad():\n",
    "            for inputs, img_names in eval_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                img_name = img_names[0]  \n",
    "                label = preds.item()\n",
    "                f.write(f\"{img_name:<20}{label}\\n\")\n",
    "\n",
    "    print(f\"Evaluation completed. Results saved to {RESULT_FILE}\")\n",
    "\n",
    "# main execution\n",
    "epochs = 10\n",
    "if __name__ == \"__main__\":\n",
    "    epochs = 10\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    train_model(epochs)\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    print(\"Validating model...\")\n",
    "    validate_model()\n",
    "\n",
    "    print(\"Evaluating model on unseen data...\")\n",
    "    evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
